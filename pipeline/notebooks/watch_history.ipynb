{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///testdata/test.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "connection = sqlite3.connect(\"testdata/test.db\")\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations.utils.io import extract_specific_files_flat, get_latest_valid_zip\n",
    "latest_valid_youtube_zip = get_latest_valid_zip(\n",
    "    \"../data/bronze/landing/google\",\n",
    "    \"*.zip\",\n",
    "    expected_file_path=\"Takeout/YouTube and YouTube Music/history\",\n",
    ")\n",
    "\n",
    "if latest_valid_youtube_zip is None:\n",
    "    raise ValueError(\"No valid zip found in folder which contains youtube data!\")\n",
    "output_folder = \"testdata/youtube\"\n",
    "extract_specific_files_flat(\n",
    "    latest_valid_youtube_zip,\n",
    "    prefix=\"Takeout/YouTube and YouTube Music/history/watch-history.html\",\n",
    "    output_path=output_folder,\n",
    ")\n",
    "html_file_path = output_folder + \"/watch-history.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_youtube_watch_history_raw(html_path: str) -> pd.DataFrame:\n",
    "    logger.info(\n",
    "        \"Finding all elements in watch history html file which contain watch history\"\n",
    "        \" info.\"\n",
    "    )\n",
    "    with open(html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, \"lxml\")\n",
    "    \n",
    "    content_cell_list = soup.find_all(\n",
    "        name='div', \n",
    "        attrs={\n",
    "            \"class\": 'content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1'\n",
    "        }\n",
    "    )\n",
    "    logger.info(f\"Found {len(content_cell_list)} elements to extract ihstory from.\")\n",
    "    errored_cells = []\n",
    "    watch_history_list: list[dict] = []\n",
    "    for index, content_cell in enumerate(content_cell_list):\n",
    "        try:\n",
    "            row = {}\n",
    "            # Extract video link and name\n",
    "            video_tag = content_cell.find('a', href=True)\n",
    "            if video_tag is None:\n",
    "                raise Exception(\"Video tag not found\")\n",
    "            row[\"video_name\"] = video_tag.text.strip()\n",
    "            row[\"video_url\"] = video_tag['href'].strip()\n",
    "\n",
    "            # Extract channel link and name (next <a> tag)\n",
    "            channel_tag = video_tag.find_next('a', href=True)\n",
    "            if channel_tag is None:\n",
    "                raise Exception(\"Channel tag not found\")\n",
    "            row[\"channel_name\"] = channel_tag.text.strip()\n",
    "            row[\"channel_url\"] = channel_tag['href'].strip()\n",
    "\n",
    "            # Extract the date (text following the channel link)\n",
    "            date_tag = channel_tag.next_sibling.next_sibling\n",
    "            if date_tag is None:\n",
    "                raise Exception(\"Date tag not found\")\n",
    "            row[\"date\"] = date_tag.strip()\n",
    "            watch_history_list.append(row)\n",
    "        except Exception:\n",
    "            errored_cells.append(content_cell)\n",
    "    \n",
    "    logger.info(\"finished extracting all watch history from html.\")\n",
    "    total_elements = len(content_cell_list)\n",
    "    successful_elements = total_elements - len(errored_cells)\n",
    "    logger.info(f\"Extracted {successful_elements}/{total_elements}\")\n",
    "    return pd.DataFrame(watch_history_list)\n",
    "\n",
    "    \n",
    "df_raw = extract_youtube_watch_history_raw(html_file_path)\n",
    "df_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.to_sql(\"youtube_watch_history_raw\", con=connection, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from youtube_watch_history_raw\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"datetime_str\"] = df[\"date\"].str.replace(\"\\u202F\", \" \").str.replace(\"\\u00A0\", \" \")\n",
    "    df = df.drop(columns=[\"date\"])\n",
    "    return df\n",
    "\n",
    "def parse_youtube_date_str(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # fix in future convert to utc\n",
    "    df[\"datetime_str\"] = df[\"datetime_str\"].str.removesuffix(\" BST\")\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime_str\"], format=\"%b %d, %Y, %I:%M:%S %p\")\n",
    "    df = df.drop(columns=[\"datetime_str\"])\n",
    "    return df\n",
    "\n",
    "def determine_video_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values(by=[\"datetime\"]).reindex()\n",
    "    # Filter only watchable content\n",
    "    df = df[df[\"video_url\"].str.contains(\"watch\")]\n",
    "    \n",
    "    df[\"next_vid_datetime\"] = df[\"datetime\"].shift(-1)\n",
    "\n",
    "    df[\"time_to_next_video\"] = (\n",
    "        (df[\"next_vid_datetime\"] - df[\"datetime\"])\n",
    "    ).dt.total_seconds()\n",
    "    # last element does not have next_vid_datetime\n",
    "    df[\"time_to_next_video\"] = df[\"time_to_next_video\"].fillna(-1)\n",
    "    # Filter vids not watched\n",
    "    df = df[(df[\"time_to_next_video\"] > 5) | (df[\"time_to_next_video\"] == -1)]\n",
    "    df.loc[df[\"time_to_next_video\"] > 90, \"video_type\"] = \"likely video\"\n",
    "    df.loc[df[\"time_to_next_video\"] <= 90, \"video_type\"] = \"likely short\"\n",
    "    df.loc[df[\"time_to_next_video\"] == -1, \"video_type\"] = \"unknown\"\n",
    "    df.loc[df[\"time_to_next_video\"] > 3 * 60 * 60, \"video_type\"] = \"unknown\"\n",
    "    df.loc[df[\"video_name\"].str.contains(\"#\"), \"video_type\"] = \"likely short\"\n",
    "    # df.loc[df[\"time_to_next_video\"]]\n",
    "    return df\n",
    "\n",
    "# I JUST REALISED HOW MUCH I HATE PANDAS \n",
    "\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * from youtube_watch_history_raw\", connection)\n",
    "df = prepare_df(df)\n",
    "df = parse_youtube_date_str(df)\n",
    "df = determine_video_type(df)\n",
    "df.to_sql(\n",
    "    \"youtube_watch_history\", \n",
    "    con= connection, \n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    ")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select channel_name, count(channel_name) from youtube_watch_history\n",
    "where video_type = \"likely short\"\n",
    "group by channel_name\n",
    "order by count(channel_name) desc\n",
    "limit 30;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select channel_name, video_name, video_url, video_type, time_to_next_video  from youtube_watch_history\n",
    "where time_to_next_video > 1000\n",
    "order by time_to_next_video desc\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
